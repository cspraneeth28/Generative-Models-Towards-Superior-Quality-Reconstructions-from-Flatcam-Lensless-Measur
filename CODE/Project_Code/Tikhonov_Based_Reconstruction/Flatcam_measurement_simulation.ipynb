{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yTjPQ2AHxAtk"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#import kornia as kr\n",
    "import scipy.io \n",
    "import numpy as np\n",
    "#import kornia as kr \n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import os\n",
    "import skimage.io\n",
    "\n",
    "mat = scipy.io.loadmat('/content/drive/MyDrive/Colab Notebooks/lensless_imaging/flatcam_calibdata.mat')\n",
    "\n",
    "cSize = np.squeeze(mat['cSize'][:, :]).astype(int)\n",
    "\n",
    "Plr  = torch.from_numpy(np.squeeze(mat['P1r'][:,:]).astype(float)).float()\n",
    "Plgb = torch.from_numpy(np.squeeze(mat['P1gb'][:,:]).astype(float)).float()\n",
    "Plgr = torch.from_numpy(np.squeeze(mat['P1gr'][:,:]).astype(float)).float()\n",
    "Plb  = torch.from_numpy(np.squeeze(mat['P1b'][:,:]).astype(float)).float()\n",
    "Qlr  = torch.from_numpy(np.squeeze(mat['Q1r'][:,:]).astype(float)).float()\n",
    "Qlgb = torch.from_numpy(np.squeeze(mat['Q1gb'][:,:]).astype(float)).float()\n",
    "Qlgr = torch.from_numpy(np.squeeze(mat['Q1gr'][:,:]).astype(float)).float()\n",
    "Qlb  = torch.from_numpy(np.squeeze(mat['Q1b'][:,:]).astype(float)).float()\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "Plr = torch.unsqueeze(Plr, 0).expand((batch_size, Plr.size()[0], Plr.size()[1]))\n",
    "Plgb = torch.unsqueeze(Plgb, 0).expand((batch_size, Plgb.size()[0], Plgb.size()[1]))\n",
    "Plgr = torch.unsqueeze(Plgr, 0).expand((batch_size, Plgr.size()[0], Plgr.size()[1]))\n",
    "Plb = torch.unsqueeze(Plb, 0).expand((batch_size, Plb.size()[0], Plb.size()[1]))\n",
    "Qlr = torch.unsqueeze(Qlr, 0).expand((batch_size, Qlr.size()[0], Qlr.size()[1]))\n",
    "Qlgb = torch.unsqueeze(Qlgb, 0).expand((batch_size, Qlgb.size()[0], Qlgb.size()[1]))\n",
    "Qlgr = torch.unsqueeze(Qlgr, 0).expand((batch_size, Qlgr.size()[0], Qlgr.size()[1]))\n",
    "Qlb = torch.unsqueeze(Qlb, 0).expand((batch_size, Qlb.size()[0], Qlb.size()[1]))\n",
    "\n",
    "\n",
    "def default_conv(in_channels, out_channels, kernel_size, bias=True):\n",
    "    return nn.Conv2d(\n",
    "        in_channels, out_channels, kernel_size,\n",
    "        padding=(kernel_size//2), bias=bias)\n",
    "\n",
    "def apply_noise(img, nSig = 10):\n",
    "    r''' This function add simulated noise '''\n",
    "    if nSig == 0:\n",
    "        return img \n",
    "    for i in range(0, img.size()[1]):\n",
    "        Y = img[i, :, :, :]\n",
    "        tempY = Y - torch.min(torch.zeros(1, device = torch.device(\"cuda\")), torch.min(Y.view(-1)))\n",
    "        normY = torch.dist(tempY, torch.zeros(1, device = torch.device(\"cuda\")), p = 2) \n",
    "        noise = torch.randn(Y.size(), device = torch.device('cuda'))\n",
    "        noise = torch.sqrt((normY / nSig) ** 2 / (Y.numel() * torch.var(noise.view(-1)) )) * noise        \n",
    "        img[i, :, :, :] = Y + noise\n",
    "\n",
    "    return img \n",
    "\n",
    "class AddNoise(nn.Module):\n",
    "    r'''Add noise for simulated measurement'''\n",
    "    def __init__(self, nSig = 10):\n",
    "        super(AddNoise, self).__init__()\n",
    "        self.nSig = nSig\n",
    "\n",
    "    def forward(self, x):\n",
    "        return apply_noise(x, self.nSig)\n",
    "\n",
    "class ApplyRaw2Bayer(nn.Module):\n",
    "    r''' Convert Raw data to Bayer pattern'''\n",
    "    def __init__(self):\n",
    "        super(ApplyRaw2Bayer, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return Raw2Bayer(x)\n",
    "\n",
    "def Raw2Bayer(x, crop_size = cSize, is_rotate = False):\n",
    "    r''' Convert FlatCam raw data to Bayer'''\n",
    "    \n",
    "    # Step 1. Convert the Image & rotate \n",
    "    c, b, h, w = x.size()\n",
    "    \n",
    "    y = torch.zeros((c, 4, int(h/2), int(w/2)), device = torch.device('cuda'))\n",
    "\n",
    "    if is_rotate:                       # ---> THIS MODES DOESNOT WORK YET!!! (2019.07.14)\n",
    "        scale = torch.ones(1)\n",
    "        angle = torch.ones(1) * 0.05 * 360              # 0.05 is angle collected from data measurements \n",
    "        center = torch.ones(1, 2)\n",
    "        center[..., 0] = int(h / 4)  # x\n",
    "        center[..., 1] = int(w / 4)  # y\n",
    "        M = kr.get_rotation_matrix2d(center, angle, scale).cuda()\n",
    "        _, _, h, w = y.size()\n",
    "        \n",
    "        y[:, 0, :, : ] = kr.warp_affine(x[:, :, 1::2, 1::2], M, dsize = (h, w))\n",
    "        y[:, 1, :, : ] = kr.warp_affine(x[:, :, 0::2, 1::2], M, dsize = (h, w))\n",
    "        y[:, 2, :, : ] = kr.warp_affine(x[:, :, 1::2, 0::2], M, dsize = (h, w))\n",
    "        y[:, 3, :, : ] = kr.warp_affine(x[:, :, 0::2, 0::2], M, dsize = (h, w))\n",
    "\n",
    "    else:\n",
    "        y[:, 0, :, : ] = x[:, 0, 1::2, 1::2]\n",
    "        y[:, 1, :, : ] = x[:, 0, 0::2, 1::2]\n",
    "        y[:, 2, :, : ] = x[:, 0, 1::2, 0::2]\n",
    "        y[:, 3, :, : ] = x[:, 0, 0::2, 0::2]\n",
    "\n",
    "    # Step 3. Crop the image \n",
    "    start_row = int((y.size()[2] - crop_size[0]) / 2) \n",
    "    end_row = start_row + crop_size[0]\n",
    "    start_col = int((y.size()[3] - crop_size[1])/2) \n",
    "    end_col = start_col + crop_size[1] \n",
    "    return y[:,:, start_row:end_row, start_col:end_col]\n",
    "\n",
    "def Bayer2RGB(x, normalize = True):\n",
    "    b, _, h, w = x.size()\n",
    "    x_rgb = torch.zeros((b, 3, h, w)).cuda()    \n",
    "    x_rgb[:, 0, :, :] = x[:, 0, :, :]\n",
    "    x_rgb[:, 1, :, :] = 0.5 * (x[:, 1, :, :]  + x[:, 2, :, :])\n",
    "    x_rgb[:, 2, :, :] = x[:, 3, :, :]\n",
    "\n",
    "    if normalize:\n",
    "        x_rgb = (x_rgb - torch.min(x_rgb.view(-1))) / (torch.max(x_rgb.view(-1)) - torch.min(x_rgb.view(-1)) )\n",
    "    \n",
    "    return x_rgb \n",
    "\n",
    "class ApplyBayer2RGB(nn.Module):\n",
    "    def __init__(self, normalize = True ):\n",
    "        super(ApplyBayer2RGB, self).__init__()\n",
    "        self.normalize = normalize\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return Bayer2RGB(x, self.normalize)\n",
    "    \n",
    "\n",
    "def flatcamSamp(x):\n",
    "    y = torch.zeros((x.size()[0], 1, Plr.size()[1] * 2, 2 * Qlr.size()[1])).to(torch.device(\"cuda\"))       \n",
    "    y[:, 0, 1::2, 1::2] = torch.bmm(torch.bmm(Plr[0:x.size()[0], :, :].cuda(),  x[:, 0, :, :].cuda()), Qlr[0:x.size()[0], :, :].cuda().permute([0, 2, 1]))\n",
    "    y[:, 0, 0::2, 1::2] = torch.bmm(torch.bmm(Plgb[0:x.size()[0], :, :].cuda(), x[:, 1, :, :].cuda()), Qlgb[0:x.size()[0], :, :].cuda().permute([0, 2, 1]))\n",
    "    y[:, 0, 1::2, 0::2] = torch.bmm(torch.bmm(Plgr[0:x.size()[0], :, :].cuda(), x[:, 1, :, :].cuda()), Qlgr[0:x.size()[0], :, :].cuda().permute([0, 2, 1]))\n",
    "    y[:, 0, 0::2, 0::2] = torch.bmm(torch.bmm(Plb[0:x.size()[0], :, :].cuda() , x[:, 2, :, :].cuda()), Qlb[0:x.size()[0], :, :].cuda().permute([0, 2, 1]))\n",
    "\n",
    "    return y \n",
    "class FlatCamSampSim(nn.Module):\n",
    "    r''' Simulated Flatcam measurement '''\n",
    "    def __init__(self, batSize):\n",
    "        super(FlatCamSampSim, self).__init__()\n",
    "        if batSize > batch_size:\n",
    "            raise Exception('batch_size should not exceed {}. Please change the corresponding batch_size values in common.py file'.format(batch_size))      \n",
    "\n",
    "    def forward(self, x):        \n",
    "        return flatcamSamp(x)\n",
    "\n",
    "class FlatCamSimInverse(nn.Module):\n",
    "    r''' Initial Reconstruction for Simulated'''\n",
    "    def __init__(self):\n",
    "        super(FlatCamSimInverse, self).__init__()           \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Step 0 Convert from raw data to bayer \n",
    "        x = Raw2Bayer(x)\n",
    "        \n",
    "        # Step 2: Simple Inverse \n",
    "        y = torch.zeros((x.size()[0], 4, Plr.size()[2], Qlr.size()[2])).to(torch.device(\"cuda\"))\n",
    "        y[:, 0, :, :] = torch.bmm(torch.bmm(Plr[0:x.size()[0], :, :].cuda().permute([0, 2, 1]),  x[:, 0, :, :]), Qlr[0:x.size()[0], :, :].cuda())        \n",
    "        y[:, 1, :, :] = torch.bmm(torch.bmm(Plgb[0:x.size()[0], :, :].cuda().permute([0, 2, 1]), x[:, 1, :, :].cuda()), Qlgb[0:x.size()[0], :, :].cuda())\n",
    "        y[:, 2, :, :] = torch.bmm(torch.bmm(Plgr[0:x.size()[0], :, :].cuda().permute([0, 2, 1]), x[:, 1, :, :].cuda()), Qlgr[0:x.size()[0], :, :].cuda())\n",
    "        y[:, 3, :, :] = torch.bmm(torch.bmm(Plb[0:x.size()[0], :, :].cuda().permute([0, 2, 1]),  x[:, 2, :, :].cuda()), Qlb[0:x.size()[0], :, :].cuda())\n",
    "\n",
    "        # Step 3: Convert to bayer pattern \n",
    "        y = F.relu(y)               # Remove negative value  --> maybe not necessary \n",
    "        y = Bayer2RGB(y)            # convert to RGB \n",
    "\n",
    "        return y \n",
    "\n",
    "def make_separable(x):\n",
    "\n",
    "    ''' function that convert separable of image'''\n",
    "    #b, c, w, h = x.size() \n",
    "\n",
    "    #for i in range(b):\n",
    "    rowMeans = torch.mean(x, 3)\n",
    "    colMeans = torch.mean(x, 2) \n",
    "    allMean = torch.mean(rowMeans, 2)\n",
    "\n",
    "    rowMeans = torch.unsqueeze(rowMeans, -1).expand(x.size())\n",
    "    colMeans = torch.unsqueeze(colMeans, 2).expand(x.size())\n",
    "    allMean = torch.unsqueeze(torch.unsqueeze(allMean, -1), -2).expand(x.size())\n",
    "\n",
    "    x = x - rowMeans - colMeans + allMean\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AS2KVP-cxz--"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize(256),\n",
    "                                #transforms.CenterCrop(224),\n",
    "                                transforms.ToTensor()])\n",
    "\n",
    "def quantize(img, rgb_range):\n",
    "    pixel_range = 255 / rgb_range\n",
    "    return img.mul(pixel_range).clamp(0, 255).round().div(pixel_range)\n",
    "\n",
    "class ImageFolderWithPaths(datasets.ImageFolder):\n",
    "    \"\"\"Custom dataset that includes image file paths. Extends\n",
    "    torchvision.datasets.ImageFolder\n",
    "    \"\"\"\n",
    "\n",
    "    # override the __getitem__ method. this is the method that dataloader calls\n",
    "    def __getitem__(self, index):\n",
    "        # this is what ImageFolder normally returns \n",
    "        image, _ = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "        path,_ = self.imgs[index]\n",
    "        image_name = os.path.basename(path)\n",
    "        return image,image_name\n",
    "\n",
    "# instantiate the dataset and dataloader\n",
    "data_dir = \"/content/drive/MyDrive/FER2013/fer2013trainvalidupdated2\"\n",
    "\n",
    "dataset1 = ImageFolderWithPaths(data_dir,transform=transform) # our custom dataset\n",
    "dataloader = DataLoader(dataset1, batch_size=128, shuffle=False)\n",
    "\n",
    "# iterate over data\n",
    "for batch_images,image_name in dataloader:\n",
    "    sai\n",
    "    img = quantize(batch_images , 255)\n",
    "    img = flatcamSamp(batch_images)\n",
    "    img = apply_noise(img, 10)\n",
    "    pad = (20,20,12,12)\n",
    "    img = F.pad(img,pad,\"constant\",0)\n",
    "    \n",
    "\n",
    "    for i in range(len(img)):\n",
    "      image =  img[i].cpu().squeeze(0).numpy()\n",
    "      skimage.io.imsave(f\"/content/drive/MyDrive/FER2013TrainValid_Flatcam_measurements/{image_name[i]}\",image)\n",
    "      \n",
    "    \n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO+AdoOBi4M4It4iBEA8/fD",
   "name": "Flatcam_measurement_simulation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
